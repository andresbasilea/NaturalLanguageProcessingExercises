{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cffd618d-5bc8-43ea-a18b-66a484cb87ad",
      "metadata": {
        "id": "cffd618d-5bc8-43ea-a18b-66a484cb87ad"
      },
      "source": [
        "# Seq2seq\n",
        "- En este notebook se define una arquitectura seq2seq para traducir oraciones del inglés al español.\n",
        "\n",
        "<img src=\"../img/seq-to-seq.png\" width=\"700\"/>\n",
        "\n",
        "__Imagen tomada de Sutskever, I., Vinyals, O., & Le, Q. V. (2014). Sequence to sequence learning with neural networks. Advances in neural information processing systems, 27.__\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "843670d1-04f9-4a46-9f1c-fa0e1b4f92d7",
      "metadata": {
        "id": "843670d1-04f9-4a46-9f1c-fa0e1b4f92d7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable tensorflow debugging logs\n",
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "257dac3e-4b4f-4eac-964d-4949e9c7c070",
      "metadata": {
        "id": "257dac3e-4b4f-4eac-964d-4949e9c7c070"
      },
      "source": [
        "## 1.- Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "16c0293e-4292-4aef-82f8-d81a0a8b35fa",
      "metadata": {
        "id": "16c0293e-4292-4aef-82f8-d81a0a8b35fa"
      },
      "outputs": [],
      "source": [
        "text_file = keras.utils.get_file(\n",
        "    fname=\"spa-eng.zip\",\n",
        "    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",\n",
        "    extract=True,\n",
        ")\n",
        "text_file = pathlib.Path(text_file).parent / \"spa-eng\" / \"spa.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "0b71cea7-5bc5-4b94-8bc3-7cee706c0fd3",
      "metadata": {
        "id": "0b71cea7-5bc5-4b94-8bc3-7cee706c0fd3"
      },
      "outputs": [],
      "source": [
        "with open(text_file) as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n",
        "    \n",
        "text_pairs = []\n",
        "for line in lines:\n",
        "    eng, spa = line.split(\"\\t\")\n",
        "    spa = \"[start] \" + spa + \" [end]\"\n",
        "    text_pairs.append((eng, spa))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "8956c567-5805-4435-94a0-453b90b498f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8956c567-5805-4435-94a0-453b90b498f7",
        "outputId": "b61f964c-575e-48f5-8789-555b9e5c9f28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('He grew old.', '[start] Él envejeció. [end]')\n",
            "(\"You're a good friend.\", '[start] Sos un buen amigo. [end]')\n",
            "('Where did you see those women?', '[start] ¿Dónde viste a esas mujeres? [end]')\n",
            "('He is working in AIDS research.', '[start] Él trabaja en investigación de SIDA. [end]')\n",
            "(\"This shouldn't be repeated.\", '[start] Esto no debería repetirse. [end]')\n"
          ]
        }
      ],
      "source": [
        "for _ in range(5):\n",
        "    print(random.choice(text_pairs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "e3cd4ad2-f792-4728-a61f-f10407f27f35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3cd4ad2-f792-4728-a61f-f10407f27f35",
        "outputId": "6b2704ed-a75f-463a-a0dc-5d12f8d1f820"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118964 total pairs\n",
            "83276 training pairs\n",
            "17844 validation pairs\n",
            "17844 test pairs\n"
          ]
        }
      ],
      "source": [
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
        "\n",
        "print(f\"{len(text_pairs)} total pairs\")\n",
        "print(f\"{len(train_pairs)} training pairs\")\n",
        "print(f\"{len(val_pairs)} validation pairs\")\n",
        "print(f\"{len(test_pairs)} test pairs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6544172c-60cc-4039-b5ef-968fd3776012",
      "metadata": {
        "id": "6544172c-60cc-4039-b5ef-968fd3776012"
      },
      "source": [
        "## 2.- Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "id": "eb61fb7f-164f-44d8-b974-1118f55f3f6d",
      "metadata": {
        "id": "eb61fb7f-164f-44d8-b974-1118f55f3f6d"
      },
      "outputs": [],
      "source": [
        "strip_chars = string.punctuation + \"¿\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "vocab_size = 20000 #Tamaño de vocabulario\n",
        "maxlen = 10\n",
        "batch_size = 64\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
        "\n",
        "eng_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size, output_mode=\"int\", \n",
        "    output_sequence_length=maxlen,\n",
        ")\n",
        "spa_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=maxlen,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "train_eng_texts = [pair[0] for pair in train_pairs]\n",
        "train_spa_texts = [pair[1] for pair in train_pairs]\n",
        "eng_vectorization.adapt(train_eng_texts)\n",
        "spa_vectorization.adapt(train_spa_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "id": "97d84341-8e27-46be-9fb3-a885633ba23e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97d84341-8e27-46be-9fb3-a885633ba23e",
        "outputId": "f69c3884-54bc-404a-cb3b-a6065a50c5c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 10), dtype=int64, numpy=\n",
              "array([[ 18, 233,   8,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [ 18, 165,   8,   0,   0,   0,   0,   0,   0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ],
      "source": [
        "eng_vectorization([['my name is'], ['my dog is']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "id": "9089253b-7dcd-4371-8b55-91f3c9bdb707",
      "metadata": {
        "id": "9089253b-7dcd-4371-8b55-91f3c9bdb707"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "id": "ab556a43-d722-45a7-8a44-9f0df5c1d7b3",
      "metadata": {
        "id": "ab556a43-d722-45a7-8a44-9f0df5c1d7b3"
      },
      "outputs": [],
      "source": [
        "def preprocess(eng, spa):\n",
        "    eng = eng_vectorization(eng)  #Codificador en ingles\n",
        "    spa = spa_vectorization(spa)  #Decodificador en espaniol\n",
        "    return tf.reverse(eng, [1]), spa[:, :-1], spa[:, 1:]\n",
        "\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, spa_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    spa_texts = list(spa_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(preprocess)\n",
        "    return dataset.shuffle(2048).prefetch(AUTOTUNE).cache()\n",
        "\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "id": "3e60e15f-35a7-496e-93e0-54c81128351d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e60e15f-35a7-496e-93e0-54c81128351d",
        "outputId": "0bcf3dfd-1758-44fa-8b07-95a9289cb43a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([  0   0   0   0   0 432   2 307  22  79], shape=(10,), dtype=int64) tf.Tensor([   2    7 4005    9  394   16   65    3    0], shape=(9,), dtype=int64) tf.Tensor([   7 4005    9  394   16   65    3    0    0], shape=(9,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "for inp_enc, inp_dec, tar_dec in train_ds.take(1):\n",
        "    print(inp_enc[0], inp_dec[0], tar_dec[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1220a01b-db62-412b-b160-d1e12547c6f3",
      "metadata": {
        "id": "1220a01b-db62-412b-b160-d1e12547c6f3"
      },
      "source": [
        "## 3.- Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "id": "36cac235-72b2-4550-9b86-dc55ef68e21c",
      "metadata": {
        "id": "36cac235-72b2-4550-9b86-dc55ef68e21c"
      },
      "outputs": [],
      "source": [
        "emb_dim = 256\n",
        "model_dim = 512"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f86988d-5d37-4f81-92f4-9dd5f2b8b661",
      "metadata": {
        "id": "1f86988d-5d37-4f81-92f4-9dd5f2b8b661"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "id": "36ba4172-b3ac-429e-8904-defdccac7394",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36ba4172-b3ac-429e-8904-defdccac7394",
        "outputId": "87b3354a-c333-4b9a-f957-7a0a87f6b716"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 512), dtype=float32, numpy=\n",
              "array([[-0.00268189,  0.00138597,  0.00644545, ..., -0.00335744,\n",
              "        -0.02368064, -0.00172296],\n",
              "       [-0.0038465 ,  0.017239  , -0.00164245, ...,  0.00845426,\n",
              "         0.0014715 ,  0.00419005],\n",
              "       [ 0.00493488, -0.00029366, -0.01341123, ..., -0.00229503,\n",
              "         0.00400272, -0.00774842],\n",
              "       ...,\n",
              "       [-0.00468742, -0.0175637 ,  0.00667318, ..., -0.01767453,\n",
              "        -0.00385535, -0.00040287],\n",
              "       [ 0.00865721,  0.00904964, -0.00212193, ...,  0.01302145,\n",
              "        -0.00205267, -0.00147501],\n",
              "       [ 0.0029376 ,  0.01555982, -0.00907552, ...,  0.00416165,\n",
              "        -0.00531697,  0.00069319]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, voc_size, emb_dim, model_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = tf.keras.layers.Embedding(voc_size,\n",
        "                                                   emb_dim)\n",
        "        self.gru = tf.keras.layers.GRU(model_dim,\n",
        "                                       return_sequences=False,\n",
        "                                       return_state=True)\n",
        "        \n",
        "    def call(self, x, state=None):\n",
        "        x = self.embedding(x)\n",
        "        x, state = self.gru(x, initial_state=state)\n",
        "        return x, state\n",
        "    \n",
        "    \n",
        "encoder = Encoder(eng_vectorization.vocabulary_size(),\n",
        "                  emb_dim, model_dim)\n",
        "output, enc_state = encoder(inp_enc)\n",
        "enc_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "id": "2fd490ee-0b1b-4cdc-9893-692aaacda333",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fd490ee-0b1b-4cdc-9893-692aaacda333",
        "outputId": "79d39d2f-3f35-41ce-9a4e-1594cb2979c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ],
      "source": [
        "output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "id": "916c397c-61aa-4df8-a426-c21fc10d20ff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "916c397c-61aa-4df8-a426-c21fc10d20ff",
        "outputId": "962e9654-1775-47ac-dcfa-5ff4e35bb6d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_12 (Embedding)    multiple                  3087104   \n",
            "                                                                 \n",
            " gru_12 (GRU)                multiple                  1182720   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,269,824\n",
            "Trainable params: 4,269,824\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "encoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "478b656b-d6c8-4bd5-9139-8aba17babe4e",
      "metadata": {
        "id": "478b656b-d6c8-4bd5-9139-8aba17babe4e"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "id": "a606a2c6-8069-4ac0-984d-f1177837fdd4",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a606a2c6-8069-4ac0-984d-f1177837fdd4",
        "outputId": "b6c22fe1-c2e9-4578-8ef1-31c76a3ff6e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 1, 20000), dtype=float32, numpy=\n",
              "array([[[ 3.4991712e-03,  4.2493772e-04,  7.3836133e-04, ...,\n",
              "          1.3449894e-03, -7.5503933e-04, -2.0426055e-04]],\n",
              "\n",
              "       [[ 2.6393642e-03,  1.0523257e-05,  5.1834190e-04, ...,\n",
              "         -1.5131941e-03, -3.0605118e-03, -1.3780618e-03]],\n",
              "\n",
              "       [[ 2.8696274e-03, -2.9542629e-04,  9.6997595e-04, ...,\n",
              "          5.4154196e-04, -1.7812977e-03, -2.3649007e-04]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 4.3738480e-03,  2.6886776e-04,  5.0340447e-04, ...,\n",
              "          4.5838271e-04, -1.2118408e-03, -4.2968406e-04]],\n",
              "\n",
              "       [[ 1.2096075e-03,  6.4217864e-04, -6.5309013e-04, ...,\n",
              "         -5.8217096e-04,  7.2521070e-04, -3.3441249e-03]],\n",
              "\n",
              "       [[ 2.3013330e-03, -8.5063197e-04, -1.0327965e-03, ...,\n",
              "         -2.1219230e-03, -2.9115155e-04, -1.3098387e-03]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, voc_size, emb_dim, model_dim):\n",
        "        super().__init__(self)\n",
        "        self.embedding = layers.Embedding(voc_size, emb_dim)\n",
        "        self.gru = layers.GRU(model_dim,\n",
        "                              return_sequences=True,\n",
        "                              return_state=True)\n",
        "        self.logits = layers.Dense(voc_size)\n",
        "\n",
        "    def call(self, x, states, return_state=False, training=False):\n",
        "        x = self.embedding(x, training=training)\n",
        "        x, states = self.gru(x, initial_state=states, training=training)\n",
        "        x = self.logits(x, training=training)\n",
        "\n",
        "        if return_state:\n",
        "            return x, states\n",
        "        else:\n",
        "            return x \n",
        "\n",
        "\n",
        "decoder = Decoder(voc_size=spa_vectorization.vocabulary_size(),\n",
        "                  emb_dim=emb_dim,\n",
        "                  model_dim=model_dim)\n",
        "\n",
        "decoder(inp_dec[:, :1], enc_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "id": "d6fd6976-05a1-446b-be33-db7b8747035e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6fd6976-05a1-446b-be33-db7b8747035e",
        "outputId": "586516e6-7465-4c1b-cb50-6dae3ce6e7ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"decoder_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_13 (Embedding)    multiple                  5120000   \n",
            "                                                                 \n",
            " gru_13 (GRU)                multiple                  1182720   \n",
            "                                                                 \n",
            " dense_6 (Dense)             multiple                  10260000  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,562,720\n",
            "Trainable params: 16,562,720\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "decoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d773b6cc-1f5c-4251-bf66-d810aba70357",
      "metadata": {
        "id": "d773b6cc-1f5c-4251-bf66-d810aba70357"
      },
      "source": [
        "## 4.- Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "id": "87162be7-ffe4-41d8-9385-db9ae41f0715",
      "metadata": {
        "id": "87162be7-ffe4-41d8-9385-db9ae41f0715"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(0.001)\n",
        "\n",
        "def loss_function(label, pred): #Funcion de pérdida para el ejercicio de tarea\n",
        "    mask = label != 0\n",
        "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "    loss = loss_object(label, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss.dtype)  #Mascara porque no todas las oraciones tienen la misma longitud, en el GPU hay que paralelizar. (zero padding, añadiendo ceros al final de palabras muy cortas)\n",
        "    loss *= mask\n",
        "\n",
        "    loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "id": "bad6a29b-b44b-4b83-8f28-50ad712cba3e",
      "metadata": {
        "id": "bad6a29b-b44b-4b83-8f28-50ad712cba3e"
      },
      "outputs": [],
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "id": "5ad8ca11-06d8-4cd1-bfc2-bb5e3c56236f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ad8ca11-06d8-4cd1-bfc2-bb5e3c56236f",
        "outputId": "8e87247a-4cb7-4840-b1a1-cb515e090213"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[  0   0   0   0  12  37   4   5 155   6]\n",
            " [  0   0   0 249 510  33  80  12  60   3]\n",
            " [  0   0   0   0   0 345 341  56 193  78]], shape=(3, 10), dtype=int64) tf.Tensor(\n",
            "[[   2    8  126    5 1850   41    3    0    0]\n",
            " [   2   88    5    7   86  762   17  364    3]\n",
            " [   2   14 1527   50  146   32  270    3    0]], shape=(3, 9), dtype=int64) tf.Tensor(\n",
            "[[   8  126    5 1850   41    3    0    0    0]\n",
            " [  88    5    7   86  762   17  364    3    0]\n",
            " [  14 1527   50  146   32  270    3    0    0]], shape=(3, 9), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "for inp_enc, inp_dec, tar_dec in train_ds.take(1):\n",
        "    print(inp_enc[:3], inp_dec[:3], tar_dec[:3])  # Oraciones terminan en ceros por padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "id": "8c95d3d9-c4e9-4400-bb4b-57d54f313f30",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c95d3d9-c4e9-4400-bb4b-57d54f313f30",
        "outputId": "f108f962-b17b-47cd-f762-8f00af26067c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 512]), TensorShape([64, 9]), TensorShape([64, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ],
      "source": [
        "_, state = encoder(inp_enc, training=True)\n",
        "state.shape, inp_dec.shape, tar_dec.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "id": "ea2bd42b-e98f-4abb-9d04-324d55b6ef44",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "ea2bd42b-e98f-4abb-9d04-324d55b6ef44"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(inp_enc, inp_dec, tar_dec):  #Agregar loop de validación\n",
        "    with tf.GradientTape() as tape:\n",
        "        _, state = encoder(inp_enc, training=True)\n",
        "        pred = decoder(inp_dec, state, training=True)\n",
        "        loss_value = loss_function(tar_dec, pred)\n",
        "        \n",
        "    weights = encoder.trainable_weights + decoder.trainable_weights #Se asignan variables tanto del codificador como decodificador para calcular pesos\n",
        "    gradients = tape.gradient(loss_value, weights)\n",
        "    optimizer.apply_gradients(zip(gradients, weights))\n",
        "    train_loss(loss_value)\n",
        "\n",
        "\n",
        "######################################################\n",
        "validation_loss = tf.keras.metrics.Mean(name=\"validation_loss\")\n",
        "validation_acc = tf.keras.metrics.Accuracy(name='validation_accuracy')\n",
        "\n",
        "@tf.function\n",
        "def test_step(inp_enc, inp_dec, tar_dec):\n",
        "    _, state = encoder(inp_enc, training=False)\n",
        "    pred = decoder(inp_dec, state, training=False)\n",
        "    loss_value = loss_function(tar_dec, pred)\n",
        "    # validation_acc(tar_dec, tf.math.round(pred))\n",
        "    validation_loss(loss_value)\n",
        "\n",
        "#####################################################     "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# def test_step(batch, model):\n",
        "#     x, y = batch            #Textos x, Etiquetas y\n",
        "#     _, state = encoder(inp_enc, training=False)\n",
        "#     pred = decoder(inp_dec, state, training=False)\n",
        "#     #output = model(x, training=False) #Pasamos texto por modelo y nos regresa lotes\n",
        "#         # Compute loss\n",
        "#     loss_value = loss_function(y, pred)\n",
        "#     validation_loss_avg(loss_value)\n",
        "#     validation_acc_avg(y, tf.math.round(pred))\n",
        "#     train_loss(loss_value)\n",
        "#     # print(loss_value,validation_loss_avg,validation_acc_avg)"
      ],
      "metadata": {
        "id": "JltxzViC2xEm"
      },
      "id": "JltxzViC2xEm",
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "id": "3a5b1064-ba11-489e-8767-f82cfbc6f34b",
      "metadata": {
        "tags": [],
        "id": "3a5b1064-ba11-489e-8767-f82cfbc6f34b"
      },
      "outputs": [],
      "source": [
        "ids_to_text = tf.keras.layers.StringLookup(\n",
        "                vocabulary=spa_vectorization.get_vocabulary(),\n",
        "                mask_token='',\n",
        "                invert=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "id": "983248bf-3db4-4263-bc4e-e29bce73df9c",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "983248bf-3db4-4263-bc4e-e29bce73df9c"
      },
      "outputs": [],
      "source": [
        "sentences = ['i love my dog',\n",
        "             'i love to sleep',\n",
        "             'the cat wants to eat']\n",
        "\n",
        "def print_translation(sentence):\n",
        "    inp = eng_vectorization([sentence])\n",
        "    inp = tf.reverse(inp, [1])\n",
        "    _, state = encoder(inp, training=False)\n",
        "    dec_inp = spa_vectorization(['[start]'])[:, :1]\n",
        "    output = []\n",
        "    pred_index = ''\n",
        "\n",
        "#Mientras la palabra predecida no sea \"End\", entonces no para\n",
        "    while pred_index != '[end]': #En el programa 3 no hay codificador ni decodificador, sólo es un transformador, por eso esto hay que modificarlo\n",
        "        logits, state = decoder(dec_inp, state, return_state=True, training=False)  #Vamos guardando estado oculto \n",
        "        dec_inp = tf.argmax(logits, axis=-1)  #Palabra que tiene la mayor probabilidad, para eso es el argmax\n",
        "        pred_index = ids_to_text(dec_inp)\n",
        "        output.append(pred_index[0][0].numpy().decode('utf-8'))\n",
        "\n",
        "    text = ' '.join(output[:-1])\n",
        "    print(f'Input: {sentence}')\n",
        "    print(f'Prediction: {text}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "id": "9cd8c900-a636-40c5-bf51-0bae31e81894",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cd8c900-a636-40c5-bf51-0bae31e81894",
        "outputId": "2616b5cd-ce5e-4f55-c29a-a3368f439533"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Time taken for epoch 1 is: 81.97 secs Loss: 4.9614\n",
            "Input: i love my dog\n",
            "Prediction: me encontré mi libro\n",
            "Input: i love to sleep\n",
            "Prediction: me encanta el trabajo\n",
            "Input: the cat wants to eat\n",
            "Prediction: el perro me dijo que me ayudaré\n",
            "\n",
            "Time taken for validation epoch 1 is: 86.38 secs Loss validation: 3.6173\n",
            "Input: i love my dog\n",
            "Prediction: me encontré mi libro\n",
            "Input: i love to sleep\n",
            "Prediction: me encanta el trabajo\n",
            "Input: the cat wants to eat\n",
            "Prediction: el perro me dijo que me ayudaré\n",
            "\n",
            "Time taken for epoch 2 is: 26.11 secs Loss: 3.0584\n",
            "Input: i love my dog\n",
            "Prediction: me encanta mi perro\n",
            "Input: i love to sleep\n",
            "Prediction: me encanta dormir\n",
            "Input: the cat wants to eat\n",
            "Prediction: el profesor me parece que se [UNK]\n",
            "\n",
            "Time taken for validation epoch 2 is: 28.60 secs Loss validation: 2.7646\n",
            "Input: i love my dog\n",
            "Prediction: me encanta mi perro\n",
            "Input: i love to sleep\n",
            "Prediction: me encanta dormir\n",
            "Input: the cat wants to eat\n",
            "Prediction: el profesor me parece que se [UNK]\n",
            "\n",
            "Time taken for epoch 3 is: 26.24 secs Loss: 2.1390\n",
            "Input: i love my dog\n",
            "Prediction: me encanta mi perro\n",
            "Input: i love to sleep\n",
            "Prediction: me encanta dormir\n",
            "Input: the cat wants to eat\n",
            "Prediction: el profesor quiere comer\n",
            "\n",
            "Time taken for validation epoch 3 is: 29.18 secs Loss validation: 2.4751\n",
            "Input: i love my dog\n",
            "Prediction: me encanta mi perro\n",
            "Input: i love to sleep\n",
            "Prediction: me encanta dormir\n",
            "Input: the cat wants to eat\n",
            "Prediction: el profesor quiere comer\n",
            "\n",
            "Time taken for epoch 4 is: 26.17 secs Loss: 1.5409\n",
            "Input: i love my dog\n",
            "Prediction: me encanta el perro\n",
            "Input: i love to sleep\n",
            "Prediction: me encanta dormir\n",
            "Input: the cat wants to eat\n",
            "Prediction: el viejo quiere comer\n",
            "\n",
            "Time taken for validation epoch 4 is: 28.57 secs Loss validation: 2.3794\n",
            "Input: i love my dog\n",
            "Prediction: me encanta el perro\n",
            "Input: i love to sleep\n",
            "Prediction: me encanta dormir\n",
            "Input: the cat wants to eat\n",
            "Prediction: el viejo quiere comer\n",
            "\n",
            "Time taken for epoch 5 is: 26.22 secs Loss: 1.1438\n",
            "Input: i love my dog\n",
            "Prediction: amo a mi perro\n",
            "Input: i love to sleep\n",
            "Prediction: me encanta dormir\n",
            "Input: the cat wants to eat\n",
            "Prediction: el gato quiere comer\n",
            "\n",
            "Time taken for validation epoch 5 is: 28.63 secs Loss validation: 2.3725\n",
            "Input: i love my dog\n",
            "Prediction: amo a mi perro\n",
            "Input: i love to sleep\n",
            "Prediction: me encanta dormir\n",
            "Input: the cat wants to eat\n",
            "Prediction: el gato quiere comer\n",
            "\n",
            "Time taken for epoch 6 is: 26.24 secs Loss: 0.8806\n",
            "Input: i love my dog\n",
            "Prediction: amo a mi perro\n",
            "Input: i love to sleep\n",
            "Prediction: me encanta dormir\n",
            "Input: the cat wants to eat\n",
            "Prediction: el gato quiere comer\n",
            "\n",
            "Time taken for validation epoch 6 is: 28.94 secs Loss validation: 2.3994\n",
            "Input: i love my dog\n",
            "Prediction: amo a mi perro\n",
            "Input: i love to sleep\n",
            "Prediction: me encanta dormir\n",
            "Input: the cat wants to eat\n",
            "Prediction: el gato quiere comer\n"
          ]
        }
      ],
      "source": [
        "epochs = 7\n",
        "\n",
        "for epoch in range(1, epochs):\n",
        "    start = time.time()\n",
        "    for inp_enc, inp_dec, tar_dec in train_ds:\n",
        "        train_step(inp_enc, inp_dec, tar_dec)\n",
        "        \n",
        "    print(f'\\nTime taken for epoch {epoch} is: {time.time() - start:.2f} secs', end=' ')\n",
        "    print(f'Loss: {train_loss.result():.4f}')\n",
        "    train_loss.reset_states()\n",
        "    \n",
        "    for s in sentences:\n",
        "        print_translation(s)\n",
        "\n",
        "\n",
        "    for inp_enc, inp_dec, tar_dec in val_ds:\n",
        "        test_step(inp_enc, inp_dec, tar_dec)\n",
        "        \n",
        "    print(f'\\nTime taken for validation epoch {epoch} is: {time.time() - start:.2f} secs', end=' ')\n",
        "    print(f'Loss validation: {validation_loss.result():.4f}')\n",
        "    validation_loss.reset_states()\n",
        "    \n",
        "    for s in sentences:\n",
        "        print_translation(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dfa7858-1f2a-492f-8a55-a454c2f3ae2a",
      "metadata": {
        "id": "2dfa7858-1f2a-492f-8a55-a454c2f3ae2a"
      },
      "source": [
        "## Ejercicio\n",
        "- Agregar loop de evaluación.\n",
        "- Mejorar el modelo con las técnicas propuestas en _Sutskever, I., Vinyals, O., & Le, Q. V. (2014). Sequence to sequence learning with neural networks. Advances in neural information processing systems, 27._\n",
        "- Agreagar mecanismo de atención de _Bahdanau_."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Tamaño de vocabulario\n",
        "- Modelo más grande\n",
        "- Modelo más profundo"
      ],
      "metadata": {
        "id": "82xLhZqn0wJ0"
      },
      "id": "82xLhZqn0wJ0"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1CDfXynC0zwm"
      },
      "id": "1CDfXynC0zwm",
      "execution_count": 170,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}